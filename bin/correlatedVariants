#!/usr/bin/env python
#
# Find correlations between substitutions using read/alignment information from
# this cmp.h5 file.  This is simply determining the significance of information
# found between substitutions co-located on a set of reads.
# The given GFF file must be derived from the given cmph5. 
#
import sys
from os import getenv
import re
import md5
import logging
import cProfile
from collections import defaultdict, namedtuple
from itertools import ifilter
from pbcore.io import CmpH5Reader, GffIO
from CorrelatedVariants.read import readMatch, completeSpan
from CorrelatedVariants.haplotype import Allele, Haplotype
from CorrelatedVariants.score import TotalCorrelation

# lookup of possible scoring algos
scorers = {'totcor': TotalCorrelation()}

def correlate():
    # load the GFF file (possibly in chunks)
    gff = GffIO.GffReader(getenv('gff'))

    # load the cmp.h5 files
    cmph5 = CmpH5Reader(getenv('cmph5'))

    # naive approach stores the read info matching the variant sites
    readhap = defaultdict(Haplotype)

    for var in gff:
        # skip indels (in case there are any)
        if var.type != 'substitution':
            continue
        
        # define a locus for locating reads from the alignment
        # at the given position +/- some bases 
        rt = cmph5.referenceInfoTable
        
        # get rid of our silly prefix (if found)
        refname = re.sub('ref\d+\|','',var.seqid)

        try:
            refid = rt[rt['FullName'] == refname][0].ID
        except IndexError:
            logging.error("Unable to locate reference '%s' in %s" 
                % (refname, cmph5.filename))
            return


        locus = (refid, var.start - 5, var.end + 5)

        # locate and record matching reads and build a picture of haplotypes
        for r in cmph5.readsInRange(*locus):
            rinfo = (r.readName, r.referenceStart, r.referenceEnd)
            readhap[rinfo].refid = refid
            readhap[rinfo].refname = refname
            if readMatch(var, r):
               readhap[rinfo].add_allele(Allele(
                    var.start, var.variantSeq, 
                    int(var.frequency), 
                    int(var.coverage)))

    hapmap = dict()
    
    # collapse the reads into their respective haplotypes
    for rinfo, hap in readhap.iteritems():
        # need to re-compute coverage based on the read subset that covers
        # this particular haplotype, store the reads so we can compute the
        # coverages within particular haplotype contexts.
        if hap.hapstr not in hapmap:
            hapmap[hap.hapstr] = hap
        hapmap[hap.hapstr].add_read(rinfo[0], expr=True)

    # finally, obtain the remaining reads that cover the haplotype, but don't
    # express it.
    for hap in ifilter(lambda x: len(x.alleles) > 0, hapmap.values()):
        locus = hap.refid, hap.span[0], hap.span[1]
        for r in completeSpan(locus, readhap.keys()):
            rname = r[0]
            if not hap.expressed(rname):
                hap.add_read(rname)
            
    # compute results
    scorer = scorers['totcor']
    scorer.hapmap = hapmap
    scorer.correlate(getenv('score') in ['True','1'])

    # output results
    out = open(getenv('out'),'w') if getenv('out') else sys.stdout
    scorer.write(out)

def usage():
    print '<cmph5=cmp.h5> <gff=gff> [out=stdout] [score=0] %s' % sys.argv[0]

# inputs:
#  cmp.h5 alignment file
#  gff file generated by GenomicConsensus rare variants algorithm
def main():
    try:
        if not getenv('cmph5') or not getenv('gff'):
            usage()
            return

        if getenv('profile'):
            cProfile.runctx("correlate()", 
                            globals=globals(), 
                            locals=locals(), 
                            filename="correlate.profile")
        else:
            correlate()

    except Exception, e:
        sys.stderr.write("%s\n" % e)
        if bool(getenv('stack')): raise

if __name__ == '__main__':
    main()
